<!DOCTYPE html>
<html>
<head>
    <title>Project 4 - CS180</title>
    <style>
        body {
            font-family: "Times New Roman", Times, serif;
            margin: 20px;
        }
        .image-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr); /* Two columns */
            gap: 20px;
            margin-top: 20px;
        }
        .image-grid img {
            width: calc(100% - 60px); /* Adjusts for 20px margin on each side */
            height: auto; /* Sets a specific height */
            margin: 0 30px; /* Adds side margins */
            object-fit: cover; /* Keeps the image within bounds without stretching */
        }
/*         .image-grid img {
            width: 100%;
            height: auto;
        } */
        .image-grid figcaption {
            text-align: center;
            font-size: 18px;
            margin-top: 5px;
            line-height: 1.5;
        }
        h1, h2, h3 {
            margin-bottom: 10px;
        }
        p, li {
            margin-bottom: 20px;
        }
        hr {
            margin: 30px 0;
        }
        center {
            text-align: center; /* Center only content within <center> tags */
        }
    </style>
</head>

<body>
    <h1>Project 4: (Auto)stitching and Photo Mosaics</h1>
    <hr width="100%" size="2">
    <h2>Overview</h2>
    <p>In this project, I continued to play with different aspects of image warping. In particular, I learned how to compute homographies to perform image mosaicing. Image mosaics were created by registering, projective warping, resampling, and compositing two or more images that I took.</p>
    <hr width="100%" size="2">

    <h2>Part 1: Computing Homographies and Warping Images</h2>

    <h3>Recovering Homographies</h3>

    <p>Before I could warp my images into alignment, I needed to recover the parameters of the transformation between each pair of images. This transformation is a homography: <b>p’ = Hp</b>, where <b>H</b> is a 3x3 matrix with 8 degrees of freedom (the lower right corner is a scaling factor, and can be set to 1). I recovered the homography for my image pairs by (1) manually creating a set of of <b>(p’,p)</b> pairs of corresponding points, and (2) using them as input parameters in the function:
    <center><code>H = computeH(im1_pts, im2_pts)</code></center>
    <p><code>im1_pts</code> and <code>im2_pts</code> are n-by-2 matrices holding the (x, y) locations of n point correspondences from the two images. <code>H</code> is the recovered 3x3 homography matrix.</p>

    <h3>Warping the Images</h3>

    <p>Now that I have the parameters of the homography, I can use the homography to warp each image towards the reference image. Let's create another function: <code>imwarped = warpImage(im, H)</code>, where <code>im</code> is the input image to be warped and <code>H</code> is the homography. I used <code>scipy.interpolate.griddata</code> along with inverse warping in my <code>warpImage</code> function and marked pixels without any mapped values as <code>NaN</code> (black).</p>

    <h3>Image Rectification</h3>

    <p>To check if everything was working correctly, I tested my code by performing "rectification" on an image of my monitor.</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/monitor.png" alt="Monitor">
            <figcaption>Original picture of monitor</figcaption>
        </figure>
        <figure>
            <img src="imgs/warped_monitor.png" alt="Warped monitor">
            <figcaption>Warped monitor</figcaption>
        </figure>
    </div>

    <p>Looks good! I know my monitor is a rectangle in real life, so I just used the four corners of the screen to compute a homography and warp it into an actual rectangle. I can do a similar rectification with this little cupboard area above my kitchen sink:</p>
    <div class="image-grid">
        <figure>
            <img src="imgs/kitchen.jpg" alt="kitchen">
            <figcaption>Original picture of kitchen</figcaption>
        </figure>
        <figure>
            <img src="imgs/warped_kitchen.png" alt="Warped kitchen">
            <figcaption>Warped kitchen</figcaption>
        </figure>
    </div>
    
    <h3>Blending Images into a Mosaic</h3>

    <p>Let's now create an image mosaic of my living room. I'll start out by taking these two pictures:</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/room1.png" alt="Living Room Photo #1">
            <figcaption>Living Room Photo #1</figcaption>
        </figure>
        <figure>
            <img src="imgs/room2.png" alt="Living Room Photo #2">
            <figcaption>Living Room Photo #2</figcaption>
        </figure>
    </div>

    <p>Using the method above, I can warp the first image of my living room to the world of the second image.</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/room1_warped.png" alt="Warped Living Room Photo #1">
            <figcaption>Warped Living Room Photo #1</figcaption>
        </figure>
    </div>

    <p>Nice. They can now perfectly overlap.</p>
    
    <div class="image-grid">
        <figure>
            <img src="imgs/simple_overlap.png" alt="simple overlap">
            <figcaption>Simple overlap</figcaption>
        </figure>
        <figure>
            <img src="imgs/intersection_color.png" alt="intersection color">
            <figcaption>Intersection shown with color (green)</figcaption>
        </figure>
    </div>

    <p>But wait. It's pretty obvious that we're just overlaying two images on top of each other, even though we have warped the first perfectly to the second with the homography. We can try and make this smoother with a simple vertical blending mask, or make use of the <code>scipy.ndimage.distance_transform_edt</code> function (mimicks MATLAB's <code>bwdist</code> function) to create a distance mask, where an alpha value weighs each pixel based on its distance from the centers of the images.</p>
    
    <div class="image-grid">
        <figure>
            <img src="imgs/vert_blend.png" alt="vert">
            <figcaption>Vertical blending</figcaption>
        </figure>
        <figure>
            <img src="imgs/radial_blend.png" alt="radial">
            <figcaption><code>bwdist</code>-like blending</figcaption>
        </figure>
    </div>

    <p>The second option looks pretty nice, so let's crop it to look more like a smooth paranoma:</p>
    <img src="imgs/radial_blend_nice.png" alt="radial">

    <p>Another with the couch in the living room:</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/couch1.jpg" alt="Living Room Photo #1">
            <figcaption>Couch Photo #1</figcaption>
        </figure>
        <figure>
            <img src="imgs/couch2.jpg" alt="Living Room Photo #2">
            <figcaption>Couch Photo #2</figcaption>
        </figure>
    </div>

    <img src="imgs/couch_blend_nice.png" alt="radial">

    <p>The warped image becomes very large and warped because the rotation from the first image to the second was relatively wide. Here's another one of a chocolate wall I saw in a candy shop in downtown SLO!</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/choco1.jpg" alt="Living Room Photo #1">
            <figcaption>Chocolate Photo #1</figcaption>
        </figure>
        <figure>
            <img src="imgs/choco2.jpg" alt="Living Room Photo #2">
            <figcaption>Chocolate Photo #2</figcaption>
        </figure>
    </div>

    <img src="imgs/choco_blend_nice.png" alt="radial">
    <p>This one turns out a little blurrier because the original photos were pretty complex (it was also hard to rotate perfectly and not shift the center of my phone camera too much).</p>

    <p>And another of my apartment's dining area:</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/dining1.jpg" alt="Dining Photo #1">
            <figcaption>Dining Room Photo #1</figcaption>
        </figure>
        <figure>
            <img src="imgs/dining2.jpg" alt="Dining Photo #2">
            <figcaption>Dining Room Photo #2</figcaption>
        </figure>
    </div>
    
    <img src="imgs/dining_blend_nice.png" alt="radial">

    <hr width="100%" size="2">
    <h2>Part 2: Automatically Stitching Images Into a Mosaic</h2>
    <p>It's a pain to have to manually choose points everytime, so it'd be cool to just automate the point stitching process (and then compute the homography, combine, and blend using the methods above). To automate, we'll follow the process outlined in <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=aa28b7a6744ce758edf96fe194363b34c3e9a91b">“Multi-Image Matching using Multi-Scale Oriented Patches” by Brown et al.</a></p>

    <h3>Harris Corners</h3>
    <p>First, we will detect Harris corners like how Section 2 (Harris Interest Point Detectors) was mentioned in the paper. Here are Harris corners overlaid on the study room I'm currently working in.</p>
    
    <div class="image-grid">
        <figure>
            <img src="imgs/wurster1.jpg" alt="Dining Photo #1">
            <figcaption>My Study Room</figcaption>
        </figure>
        <figure>
            <img src="imgs/wurster1_harris.png" alt="Dining Photo #2">
            <figcaption>Harris Corners of my study room</figcaption>
        </figure>
    </div>

    <p>That's a lot of points. Let's implement Adaptive Non-Maximal Suppression (from Section 3 of the Brown paper), so that we can narrow it down to a smaller amount to input into RANSAC after this.</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/wurster1_filtered1.png" alt="Dining Photo #1">
            <figcaption>Picture 1, after ANMS</figcaption>
        </figure>
        <figure>
            <img src="imgs/wurster2_filtered1.png" alt="Dining Photo #2">
            <figcaption>Picture 2, after ANMS</figcaption>
        </figure>
    </div>

    <p>That's still a lot of points! And some of them aren't perfectly aligned. After this we will match feature descriptors by using the surrounding areas around each point (feature patches) as  64-dimensional vectors. We can compute the 1-NN and 2-NN of each feature patch using Euclidean distance as a metric, and use the Lowe ratio to determine a "good match": if the distance of the 1-NN divided by the distance of the 2-NN is less than our ratio (e.g. 0.7), then we know the 1-NN patch in the other image is likely to be a pretty good match given the surrounding context.</p>

    <p>To detail my <code>extract_feature_descriptors</code> and <code>match_features</code> functions a little, I implemented Gaussian blurring and anti-aliasing before sampling a 40x40 patch down to 8x8. I chose to do this for each of the 3 RGB channels (then normalizing) rather than just grayscale to get slightly improved matching results.</p>

    <p>After this, we'll still have quite a few patches, so that's why we have one more step with RANSAC (random sample consensus) to narrow it down even further.</p>
        

    <div class="image-grid">
        <figure>
            <img src="imgs/wurster1_filtered2.png" alt="Dining Photo #1">
            <figcaption>Picture 1, after ANMS + RANSAC</figcaption>
        </figure>
        <figure>
            <img src="imgs/wurster2_filtered2.png" alt="Dining Photo #2">
            <figcaption>Picture 2, after ANMS + RANSAC</figcaption>
        </figure>
    </div>
    
    <p>We use these remaining points as input to our <code>computeH</code> function from above, then use the resulting homography to warp the first image to the second, and finally combine and blend using the distance mask from above.</p>

    <img src="imgs/wurster_blend_nice.png" alt="radial">

    <p>More base images:</p>

    <div class="image-grid">
        <figure>
            <img src="imgs/poles1.jpg" alt="Dining Photo #1">
            <figcaption>Let's auto-warp + combine this image of this parking alley to...</figcaption>
        </figure>
        <figure>
            <img src="imgs/poles2.jpg" alt="Dining Photo #2">
            <figcaption>... this image of the parking alley!</figcaption>
        </figure>
    </div>

     <p>The final result!</p>

    <img src="imgs/poles_blend_nice.png" alt="radial">

    <p>One last example with this storefront in downtown SLO.</p>
        
    <div class="image-grid">
        <figure>
            <img src="imgs/fizz1.jpg" alt="Dining Photo #1">
            <figcaption>Fizz Image 1</figcaption>
        </figure>
        <figure>
            <img src="imgs/fizz2.jpg" alt="Dining Photo #2">
            <figcaption>Fizz Image 2</figcaption>
        </figure>
    </div>
    
    <p>The final result!</p>

    <img src="imgs/fizz_blend_nice.png" alt="radial">
    
    <hr width="100%" size="2">
    <h2>Reflection</h2>
    <p>The coolest thing I learned from this project is how easily the human visual perspective can be mimicked with a simple homography matrix!  The features extraction was also interesting because of how it mimicks how humans pick out important points in images, and then how we use those points (although many, many more of them than in this project) to quickly merge one frame of our vision to the next.</p>

</body>
</html>
